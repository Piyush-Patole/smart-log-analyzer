ğŸ§  Disclaimer
This project was created based on my original idea and developed with the assistance of AI tools, including ChatGPT by OpenAI. I used AI primarily to help with code generation, bug fixing, and writing documentation. All architectural decisions, problem statements, and final integrations were made by me, demonstrating my ability to leverage advanced tools effectively in real-world software development.



## ğŸ” Smart Log Analyzer with AI Suggestions

An intelligent log file analysis tool that parses unstructured logs, classifies errors using NLP, and generates fix suggestionsâ€”automating part of the debugging process. Designed for DevOps, SREs, and developers to save time on log analysis and issue resolution.

---

## ğŸš€ Project Motivation

I built this project as a **Tech Associate** with 1 year of experience, with the goal of:
- Strengthening skills in Python, NLP, and data engineering
- Creating a job-ready portfolio project
- Solving a real-world problem: **debugging logs efficiently**

---

## ğŸ’¡ Key Features

| Feature | Description |
|--------|-------------|
| ğŸ” Log Parsing | Supports reading plain-text logs |
| ğŸ§  AI-based Classification | Uses NLP to group and label error types |
| ğŸ§° Auto Suggestions | Maps known patterns to likely fixes |
| ğŸ“Š Summary Reporting | Saves visual summary and detailed CSV/JSON reports |
| ğŸ”— Helpful Resources | Links error patterns to relevant docs or Stack Overflow |
| ğŸ§© Modular Design | Easy to extend for multiple log formats or error types |

---

## ğŸ—ï¸ Project Architecture

```

smart-log-analyzer/
â”‚
â”œâ”€â”€ logs/               # Sample or user log files
â”œâ”€â”€ reports/            # Output reports (CSV, JSON, PNG)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ reader.py       # Reads log file into DataFrame
â”‚   â”œâ”€â”€ parser.py       # Extracts and structures error info
â”‚   â”œâ”€â”€ classifier.py   # Categorizes errors with NLP
â”‚   â”œâ”€â”€ suggester.py    # Suggests fixes based on rules/patterns
â”‚   â”œâ”€â”€ reporter.py     # Saves reports & visualizations
â”‚   â””â”€â”€ main.py         # Entry point
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## ğŸ§  Tech Stack & Justification

| Tool/Library | Purpose | Why this tool? | Alternatives |
|--------------|---------|----------------|--------------|
| **Python** | Primary language | Fast prototyping, strong ecosystem | Java, Go |
| **Pandas** | Log storage and analysis | Data manipulation is easy | Dask, Polars |
| **spaCy** | NLP for error classification | Lightweight, production-ready | NLTK, HuggingFace |
| **Regex** | Pattern matching | Ideal for extracting timestamps/errors | Parsers, PyParsing |
| **Seaborn & Matplotlib** | Visualization of errors | Easy for summaries | Plotly, Bokeh |
| **JSON, CSV** | Report formats | Standard for log/reporting data | XML, YAML |

> ğŸ”— **Inspiration/Reference:** [Salesforce LogAI](https://github.com/salesforce/logai)

---

## ğŸ”§ Installation & Setup

### ğŸ› ï¸ Prerequisites
- Python 3.9+
- Git
- Conda (Recommended) or virtualenv

### ğŸ“¥ Step-by-Step Setup

```bash
# Step 1: Clone the repo
git clone https://github.com/yourusername/smart-log-analyzer.git
cd smart-log-analyzer

# Step 2: Create environment
conda create -n loganalyzer python=3.9
conda activate loganalyzer

# Step 3: Install dependencies
pip install -r requirements.txt

# Step 4: Download spaCy model
python -m spacy download en_core_web_sm
````

---

## ğŸ” How to Use

### ğŸ“ Prepare Logs

Place your `.log` files in the `logs/` folder. Example file: `logs/plain.log`

### â–¶ï¸ Run the Analyzer

```bash
python -m src.main logs/plain.log default
```

### ğŸ“¤ Output

| File                  | Location   | Description                          |
| --------------------- | ---------- | ------------------------------------ |
| `enriched_output.csv` | `reports/` | Logs with categories and suggestions |
| `error_summary.json`  | `reports/` | Counts of each error type            |
| `error_summary.png`   | `reports/` | Bar chart of error distribution      |

---

## ğŸ“¸ Sample Output Preview

```
Input Log:
[2024-05-10 11:35:26] ERROR: Database connection failed
[2024-05-10 11:35:45] WARNING: Deprecated API used

Output CSV:
timestamp                | level   | message                       | category        | suggestion
------------------------|---------|-------------------------------|------------------|----------------------------
2024-05-10 11:35:26     | ERROR   | Database connection failed    | Database Error   | Check database settings.
2024-05-10 11:35:45     | WARNING | Deprecated API used           | Unknown          | Refer to docs or StackOverflow
```

---

## ğŸ”¬ Under the Hood

### 1. `reader.py`

Reads a plain log file and loads lines into a Pandas DataFrame.

### 2. `parser.py`

Uses regex to extract timestamps, error levels, and messages.

### 3. `classifier.py`

Uses spaCyâ€™s NLP model to classify log lines into categories like:

* Database Error
* Timeout
* Not Found
* Unknown

### 4. `suggester.py`

Maps each category to predefined suggestions. Can be extended with GPT API or retrieval-augmented generation.

### 5. `reporter.py`

Generates:

* A CSV with full details
* JSON summary
* PNG chart using Seaborn

---

## ğŸŒ± Future Enhancements

* [ ] Support JSON, syslog & Apache formats
* [ ] Integrate GPT for smarter suggestions
* [ ] Real-time log stream analysis
* [ ] GUI or web dashboard (Streamlit/FastAPI)

---

## ğŸ§  Learning Outcomes

* ğŸ§© Modular Python architecture
* ğŸ¤– NLP classification using spaCy
* ğŸ Pandas data engineering
* ğŸ“Š Automated visualization
* ğŸ“ Real-world log parsing and debugging

---

## ğŸ“š Credits & Resources

* [Salesforce LogAI](https://github.com/salesforce/logai)
* [spaCy NLP](https://spacy.io/)
* [Pandas Documentation](https://pandas.pydata.org/)
* [Seaborn Visualization](https://seaborn.pydata.org/)
* Stack Overflow patterns dataset (self-curated)


